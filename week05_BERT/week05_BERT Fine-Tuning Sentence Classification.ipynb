{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Copy of BERT Fine-Tuning Sentence Classification.ipynb","provenance":[{"file_id":"https://github.com/ml-mipt/ml-mipt/blob/advanced/week05_BERT_and_LDA/week05_BERT_Fine_Tunning.ipynb","timestamp":1597669411175}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Py3 research env","language":"python","name":"py3_research"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"jNKaJz5j_ylj"},"source":["## week05: BERT fine tunning\n","*Based on [BERT Fine-Tuning Sentence Classification notebook on Colab](https://colab.research.google.com/drive/1ywsvwO6thOVOrfagjjfuxEf6xVRxbUNO#scrollTo=6J-FYdx6nFE_), refined by [Anastasia Ianina](https://www.linkedin.com/in/anastasia-ianina/)*"]},{"cell_type":"markdown","metadata":{"id":"5rTupQLzg8WS","colab_type":"text"},"source":["We will use BERT implementation from `pytorch-transformers` library, which contains almost all recent architectures."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"0NmMdkZO8R6q","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1597684828044,"user_tz":-180,"elapsed":7769,"user":{"displayName":"Максим Мухортов","photoUrl":"","userId":"13948818793795969641"}},"outputId":"42c36282-22ff-41e9-f658-440ff034d6e8"},"source":["! pip install pytorch-transformers\n","! wget -O negative.csv 'https://www.dropbox.com/s/r6u59ljhhjdg6j0/negative.csv?dl=0'\n","! wget -O positive.csv 'https://www.dropbox.com/s/fnpq3z4bcnoktiv/positive.csv?dl=0'"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: pytorch-transformers in /usr/local/lib/python3.6/dist-packages (1.2.0)\n","Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.6.0+cu101)\n","Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (2019.12.20)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (2.23.0)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (0.0.43)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.14.37)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (0.1.91)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.18.5)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (4.41.1)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->pytorch-transformers) (0.16.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (2020.6.20)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (3.0.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers) (0.16.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers) (7.1.2)\n","Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (0.3.3)\n","Requirement already satisfied: botocore<1.18.0,>=1.17.37 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (1.17.37)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (0.10.0)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.37->boto3->pytorch-transformers) (2.8.1)\n","Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.37->boto3->pytorch-transformers) (0.15.2)\n","--2020-08-17 17:20:24--  https://www.dropbox.com/s/r6u59ljhhjdg6j0/negative.csv?dl=0\n","Resolving www.dropbox.com (www.dropbox.com)... 162.125.1.1, 2620:100:6016:1::a27d:101\n","Connecting to www.dropbox.com (www.dropbox.com)|162.125.1.1|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: /s/raw/r6u59ljhhjdg6j0/negative.csv [following]\n","--2020-08-17 17:20:24--  https://www.dropbox.com/s/raw/r6u59ljhhjdg6j0/negative.csv\n","Reusing existing connection to www.dropbox.com:443.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://ucb1fa9d94726eea22bac214a12b.dl.dropboxusercontent.com/cd/0/inline/A9rkdMuTqnLDqSRXd9h6VdGmVtWCGtqnQcYhHHcTACMztZ2_6k8sgXSJu4HA-CuTQHX8FiKZNhUJRwmsFQkBY6D18WLIjCXyCs1W809e29x90w/file# [following]\n","--2020-08-17 17:20:24--  https://ucb1fa9d94726eea22bac214a12b.dl.dropboxusercontent.com/cd/0/inline/A9rkdMuTqnLDqSRXd9h6VdGmVtWCGtqnQcYhHHcTACMztZ2_6k8sgXSJu4HA-CuTQHX8FiKZNhUJRwmsFQkBY6D18WLIjCXyCs1W809e29x90w/file\n","Resolving ucb1fa9d94726eea22bac214a12b.dl.dropboxusercontent.com (ucb1fa9d94726eea22bac214a12b.dl.dropboxusercontent.com)... 162.125.1.15, 2620:100:6016:15::a27d:10f\n","Connecting to ucb1fa9d94726eea22bac214a12b.dl.dropboxusercontent.com (ucb1fa9d94726eea22bac214a12b.dl.dropboxusercontent.com)|162.125.1.15|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 24450101 (23M) [text/plain]\n","Saving to: ‘negative.csv’\n","\n","negative.csv        100%[===================>]  23.32M  74.6MB/s    in 0.3s    \n","\n","2020-08-17 17:20:25 (74.6 MB/s) - ‘negative.csv’ saved [24450101/24450101]\n","\n","--2020-08-17 17:20:26--  https://www.dropbox.com/s/fnpq3z4bcnoktiv/positive.csv?dl=0\n","Resolving www.dropbox.com (www.dropbox.com)... 162.125.1.1, 2620:100:6016:1::a27d:101\n","Connecting to www.dropbox.com (www.dropbox.com)|162.125.1.1|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: /s/raw/fnpq3z4bcnoktiv/positive.csv [following]\n","--2020-08-17 17:20:26--  https://www.dropbox.com/s/raw/fnpq3z4bcnoktiv/positive.csv\n","Reusing existing connection to www.dropbox.com:443.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://uc070b86ffd608883b69b814ed71.dl.dropboxusercontent.com/cd/0/inline/A9rRL3J82hrYVKPUYWdTzUoqyXALu6QgEe0vaF7HnJpXtTChnBIasY_bMG40v3kkZw9SpXVE7bedvlmr8bAyW6EJBK3Q5uoao6PcmGCxNjLpkg/file# [following]\n","--2020-08-17 17:20:26--  https://uc070b86ffd608883b69b814ed71.dl.dropboxusercontent.com/cd/0/inline/A9rRL3J82hrYVKPUYWdTzUoqyXALu6QgEe0vaF7HnJpXtTChnBIasY_bMG40v3kkZw9SpXVE7bedvlmr8bAyW6EJBK3Q5uoao6PcmGCxNjLpkg/file\n","Resolving uc070b86ffd608883b69b814ed71.dl.dropboxusercontent.com (uc070b86ffd608883b69b814ed71.dl.dropboxusercontent.com)... 162.125.1.15, 2620:100:6016:15::a27d:10f\n","Connecting to uc070b86ffd608883b69b814ed71.dl.dropboxusercontent.com (uc070b86ffd608883b69b814ed71.dl.dropboxusercontent.com)|162.125.1.15|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 26233379 (25M) [text/plain]\n","Saving to: ‘positive.csv’\n","\n","positive.csv        100%[===================>]  25.02M  81.6MB/s    in 0.3s    \n","\n","2020-08-17 17:20:27 (81.6 MB/s) - ‘positive.csv’ saved [26233379/26233379]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Ok002ceNB8E7","colab":{},"executionInfo":{"status":"ok","timestamp":1597684830652,"user_tz":-180,"elapsed":706,"user":{"displayName":"Максим Мухортов","photoUrl":"","userId":"13948818793795969641"}}},"source":["import torch\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from keras.preprocessing.sequence import pad_sequences\n","from sklearn.model_selection import train_test_split\n","from pytorch_transformers import BertTokenizer, BertConfig\n","from pytorch_transformers import AdamW, BertForSequenceClassification\n","from tqdm import tqdm, trange\n","import pandas as pd\n","import io\n","import numpy as np\n","from sklearn.metrics import accuracy_score\n","import matplotlib.pyplot as plt"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RcATv_hkg8Wb","colab_type":"text"},"source":["Если у вас есть GPU, будем использовать ее для обучения. Тем не менее, этот ноутбук можно выполнить и с помощью только CPU. Правда, это будет значительно дольше."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"oYsV4H8fCpZ-","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1597684831837,"user_tz":-180,"elapsed":440,"user":{"displayName":"Максим Мухортов","photoUrl":"","userId":"13948818793795969641"}},"outputId":"6eb2e72f-4673-4e68-c462-f03c98461230"},"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","if device == torch.device('cpu'):\n","    print('Using cpu')\n","else:\n","    n_gpu = torch.cuda.device_count()\n","    print('Using {} GPUs'.format(torch.cuda.get_device_name(0)))"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Using Tesla T4 GPUs\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"guw6ZNtaswKc"},"source":["## Загрузка данных\n"]},{"cell_type":"markdown","metadata":{"id":"W2WjHNA7g8Wf","colab_type":"text"},"source":["Мы выбрали не очень известный, необычный датасет с разметкой сентимента русскоязычных твитов (подробнее про него в [статье](http://www.swsys.ru/index.php?page=article&id=3962&lang=)). В корпусе, который мы использовали 114,911 положительных и 111,923 отрицательных записей. Загрузить его можно [тут](https://study.mokoron.com/)."]},{"cell_type":"code","metadata":{"id":"KV4J77Clg8Wf","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597684835980,"user_tz":-180,"elapsed":1744,"user":{"displayName":"Максим Мухортов","photoUrl":"","userId":"13948818793795969641"}}},"source":["import pandas as pd\n","\n","pos_texts = pd.read_csv('positive.csv', encoding='utf8', sep=';', header=None)\n","neg_texts = pd.read_csv('negative.csv', encoding='utf8', sep=';', header=None)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"dq4H2H30g8Wj","colab_type":"code","colab":{},"outputId":"75873938-9981-402c-bcbc-084f68d84640"},"source":["pos_texts.sample(5)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","      <th>11</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>3138</td>\n","      <td>409045766708396032</td>\n","      <td>1386359085</td>\n","      <td>daisy_twits</td>\n","      <td>@view_kaah с мамой к родственникам:) там мои к...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1793</td>\n","      <td>59</td>\n","      <td>36</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <td>45536</td>\n","      <td>409986865484554240</td>\n","      <td>1386583460</td>\n","      <td>Alyshovj</td>\n","      <td>RT @RashkinV: Сегодня в Большом пройдёт совмес...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>77</td>\n","      <td>2</td>\n","      <td>17</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <td>103044</td>\n","      <td>411108352207233024</td>\n","      <td>1386850843</td>\n","      <td>_lifad_</td>\n","      <td>RT @Miruim_: @_lifad_ Вольф блин, я ж офигела....</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>14391</td>\n","      <td>569</td>\n","      <td>207</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <td>56635</td>\n","      <td>410117243792400384</td>\n","      <td>1386614545</td>\n","      <td>Ideas_0_aloud</td>\n","      <td>@korean_banan один из самых офигенных твиттерс...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>7033</td>\n","      <td>144</td>\n","      <td>61</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <td>46924</td>\n","      <td>410002509415997440</td>\n","      <td>1386587190</td>\n","      <td>detkaimpala67</td>\n","      <td>@KatarinGlambert привет :3 ахах просто так сил...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>6758</td>\n","      <td>1229</td>\n","      <td>234</td>\n","      <td>7</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                        0           1              2   \\\n","3138    409045766708396032  1386359085    daisy_twits   \n","45536   409986865484554240  1386583460       Alyshovj   \n","103044  411108352207233024  1386850843        _lifad_   \n","56635   410117243792400384  1386614545  Ideas_0_aloud   \n","46924   410002509415997440  1386587190  detkaimpala67   \n","\n","                                                       3   4   5   6   7   \\\n","3138    @view_kaah с мамой к родственникам:) там мои к...   1   0   0   0   \n","45536   RT @RashkinV: Сегодня в Большом пройдёт совмес...   1   0   6   0   \n","103044  RT @Miruim_: @_lifad_ Вольф блин, я ж офигела....   1   0   1   0   \n","56635   @korean_banan один из самых офигенных твиттерс...   1   0   0   0   \n","46924   @KatarinGlambert привет :3 ахах просто так сил...   1   0   0   0   \n","\n","           8     9    10  11  \n","3138     1793    59   36   1  \n","45536      77     2   17   0  \n","103044  14391   569  207   5  \n","56635    7033   144   61   0  \n","46924    6758  1229  234   7  "]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"kylWabDNg8Wn","colab_type":"text"},"source":["Обратите внимание на специальные токены [CLS] и [SEP], которые мы добавляем в началои конец предложения."]},{"cell_type":"code","metadata":{"id":"9rkKdbMQg8Wn","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597684908149,"user_tz":-180,"elapsed":920,"user":{"displayName":"Максим Мухортов","photoUrl":"","userId":"13948818793795969641"}}},"source":["sentences = np.concatenate([pos_texts[3].values, neg_texts[3].values])\n","\n","sentences = [\"[CLS] \" + sentence + \" [SEP]\" for sentence in sentences]\n","labels = [[1] for _ in range(pos_texts.shape[0])] + [[0] for _ in range(neg_texts.shape[0])]\n"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"hPZ3eE0eg8Wq","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597684909735,"user_tz":-180,"elapsed":619,"user":{"displayName":"Максим Мухортов","photoUrl":"","userId":"13948818793795969641"}}},"source":["assert len(sentences) == len(labels) == pos_texts.shape[0] + neg_texts.shape[0]"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"AuAE4vTtg8Wt","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1597684911088,"user_tz":-180,"elapsed":583,"user":{"displayName":"Максим Мухортов","photoUrl":"","userId":"13948818793795969641"}},"outputId":"e74b405d-d3b7-4567-c8d0-2a508e4387a7"},"source":["print(sentences[1000])"],"execution_count":12,"outputs":[{"output_type":"stream","text":["[CLS] Дим, ты помогаешь мне, я тебе, все взаимно, все правильно) [SEP]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pvMsQnM2g8Wv","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597684918851,"user_tz":-180,"elapsed":613,"user":{"displayName":"Максим Мухортов","photoUrl":"","userId":"13948818793795969641"}}},"source":["from sklearn.model_selection import train_test_split\n","\n","train_sentences, test_sentences, train_gt, test_gt = train_test_split(sentences, labels, test_size=0.3)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"XZKH7Pklg8Wy","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1597684920154,"user_tz":-180,"elapsed":744,"user":{"displayName":"Максим Мухортов","photoUrl":"","userId":"13948818793795969641"}},"outputId":"c6fc148c-7a06-4447-9643-f1d33153f02c"},"source":["print(len(train_gt), len(test_gt))"],"execution_count":14,"outputs":[{"output_type":"stream","text":["158783 68051\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ex5O1eV-Pfct"},"source":["## Inputs"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"BTREubVNFiz4"},"source":["Теперь импортируем токенизатор для BERT'а, который превратит наши тексты в набор токенов, соответствующих тем, что встречаются в словаре предобученной модели."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Z474sSC6oe7A","colab":{"base_uri":"https://localhost:8080/","height":71},"executionInfo":{"status":"ok","timestamp":1597685185114,"user_tz":-180,"elapsed":69744,"user":{"displayName":"Максим Мухортов","photoUrl":"","userId":"13948818793795969641"}},"outputId":"74afc31c-2bc3-4808-e16c-bc84c9c448eb"},"source":["from pytorch_transformers import BertTokenizer, BertConfig\n","\n","\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n","\n","tokenized_texts = [tokenizer.tokenize(sent) for sent in train_sentences]\n","print (tokenized_texts[0])"],"execution_count":15,"outputs":[{"output_type":"stream","text":["100%|██████████| 231508/231508 [00:00<00:00, 1208656.05B/s]\n"],"name":"stderr"},{"output_type":"stream","text":["['[CLS]', 'н', '##а', '##ш', '##е', '##л', 'п', '##о', '##с', '##т', 'с', 'т', '##е', '##г', '##о', '##м', '*', 'no', '##idi', '##ots', 'и', 'л', '##и', '##н', '##к', '##о', '##м', 'н', '##а', 'с', '##в', '##о', '##и', 'п', '##о', '##с', '##т', 'с', 'т', '##е', '##г', '##о', '##м', '*', 'no', '##py', '##th', '##on', ')', '[SEP]']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"87_kXUeT2-br"},"source":["BERT'у нужно предоставить специальный формат входных данных.\n","\n","\n","- **input ids**: последовательность чисел, отождествляющих каждый токен с его номером в словаре.\n","- **labels**: вектор из нулей и единиц. В нашем случае нули обозначают негативную эмоциональную окраску, единицы - положительную.\n","- **segment mask**: (необязательно) последовательность нулей и единиц, которая показывает, состоит ли входной текст из одного или двух предложений. Для случая одного предложения получится вектор из одних нулей. Для двух: <length_of_sent_1> нулей и <length_of_sent_2> единиц.\n","- **attention mask**: (необязательно) последовательность нулей и единиц, где единицы обозначают токены предложения, нули - паддинг."]},{"cell_type":"markdown","metadata":{"id":"iwGC76vbg8W6","colab_type":"text"},"source":["Паддинг нужен для того, чтобы BERT мог работать с предложениями разной длины. Выбираем максимально возможную длину предложения (в нашем случае пусть это будет 100). \n","\n","Теперь более длинные предложения будем обрезать до 100 токенов, а для более коротких использовать паддинг. Возьмем готовую функцию `pad_sequences` из библиотеки `keras`.\n","\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Cp9BPRd1tMIo","colab":{},"executionInfo":{"status":"ok","timestamp":1597685725592,"user_tz":-180,"elapsed":20035,"user":{"displayName":"Максим Мухортов","photoUrl":"","userId":"13948818793795969641"}}},"source":["input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n","input_ids = pad_sequences(\n","    input_ids,\n","    maxlen=100,\n","    dtype=\"long\",\n","    truncating=\"post\",\n","    padding=\"post\"\n",")\n","attention_masks = [[float(i>0) for i in seq] for seq in input_ids]"],"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Zu44S2Zag8W8","colab_type":"text"},"source":["Делим данные на `train` и `val`:"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"aFbE-UHvsb7-","colab":{},"executionInfo":{"status":"ok","timestamp":1597685818151,"user_tz":-180,"elapsed":691,"user":{"displayName":"Максим Мухортов","photoUrl":"","userId":"13948818793795969641"}}},"source":["train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(\n","    input_ids, train_gt, \n","    random_state=42,\n","    test_size=0.1\n",")\n","\n","train_masks, validation_masks, _, _ = train_test_split(\n","    attention_masks,\n","    input_ids,\n","    random_state=42,\n","    test_size=0.1\n",")"],"execution_count":20,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7Kksia2lg8XB","colab_type":"text"},"source":["Преобразуем данные в `pytorch` тензоры:"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"jw5K2A5Ko1RF","colab":{},"executionInfo":{"status":"ok","timestamp":1597686072901,"user_tz":-180,"elapsed":2212,"user":{"displayName":"Максим Мухортов","photoUrl":"","userId":"13948818793795969641"}}},"source":["train_inputs = torch.tensor(train_inputs)\n","train_labels = torch.tensor(train_labels)\n","train_masks = torch.tensor(train_masks)"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"a2kabmVQg8XE","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597686074494,"user_tz":-180,"elapsed":1164,"user":{"displayName":"Максим Мухортов","photoUrl":"","userId":"13948818793795969641"}}},"source":["validation_inputs = torch.tensor(validation_inputs)\n","validation_labels = torch.tensor(validation_labels)\n","validation_masks = torch.tensor(validation_masks)"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"lmjrmvmug8XH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":136},"executionInfo":{"status":"ok","timestamp":1597686076805,"user_tz":-180,"elapsed":673,"user":{"displayName":"Максим Мухортов","photoUrl":"","userId":"13948818793795969641"}},"outputId":"776d30af-e54f-4dc1-bb67-8131da7c429f"},"source":["train_labels"],"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1],\n","        [1],\n","        [0],\n","        ...,\n","        [1],\n","        [1],\n","        [0]])"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"markdown","metadata":{"id":"XTHQfT09g8XK","colab_type":"text"},"source":["Воспользуемся классом `DataLoader`. Это поможет нам использовать эффективнее память во время тренировки модели, так как нам не нужно будет загружать в память весь датасет. Данные по батчам будем разбивать произвольно с помощью RandomSampler. Также обратите внимание на размер батча: если во время тренировки возникнет `Memory Error`, размер батча необходимо уменьшить."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"GEgLpFVlo1Z-","colab":{},"executionInfo":{"status":"ok","timestamp":1597686084673,"user_tz":-180,"elapsed":757,"user":{"displayName":"Максим Мухортов","photoUrl":"","userId":"13948818793795969641"}}},"source":["train_data = TensorDataset(train_inputs, train_masks, train_labels)\n","train_dataloader = DataLoader(\n","    train_data,\n","    sampler=RandomSampler(train_data),\n","    batch_size=32\n",")"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"RpAqMsyzg8XM","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597686084674,"user_tz":-180,"elapsed":494,"user":{"displayName":"Максим Мухортов","photoUrl":"","userId":"13948818793795969641"}}},"source":["validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n","validation_dataloader = DataLoader(\n","    validation_data,\n","    sampler=SequentialSampler(validation_data),\n","    batch_size=32\n",")"],"execution_count":25,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"pNl8khAhPYju"},"source":["## Обучение модели"]},{"cell_type":"markdown","metadata":{"id":"rDqLbNKOg8XP","colab_type":"text"},"source":["Теперь когда данные подготовлены, надо написать пайплайн обучения модели.\n","\n","Для начала мы хотим изменить предобученный BERT так, чтобы он выдавал метки для классификации текстов, а затем файнтюнить его на наших данных. Мы возьмем готовую модификацию BERTа для классификации из pytorch-transformers. Она интуитивно понятно называется `BertForSequenceClassification`. Это обычный BERT с добавленным линейным слоем для классификации."]},{"cell_type":"markdown","metadata":{"id":"kwzoOa5-g8XP","colab_type":"text"},"source":["Загружаем [BertForSequenceClassification](https://github.com/huggingface/pytorch-pretrained-BERT/blob/master/pytorch_pretrained_bert/modeling.py#L1129):"]},{"cell_type":"code","metadata":{"id":"mzdWpkhfg8XQ","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597686427430,"user_tz":-180,"elapsed":686,"user":{"displayName":"Максим Мухортов","photoUrl":"","userId":"13948818793795969641"}}},"source":["from pytorch_transformers import AdamW, BertForSequenceClassification"],"execution_count":26,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GcCxTDLeg8XS","colab_type":"text"},"source":["Аналогичные модели есть и для других задач. Все они построены на основе одной и той же архитектуры и различаются только верхними слоями."]},{"cell_type":"code","metadata":{"id":"f3dFAjqng8XT","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597686427810,"user_tz":-180,"elapsed":445,"user":{"displayName":"Максим Мухортов","photoUrl":"","userId":"13948818793795969641"}}},"source":["from pytorch_transformers import BertForQuestionAnswering, BertForTokenClassification"],"execution_count":27,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CQgUO2vXg8XV","colab_type":"text"},"source":["Теперь подробнее рассмотрим процесс файн-тюнинга. Как мы помним, первый токен в каждом предложении - это `[CLS]`. В отличие от скрытого состояния, относящего к обычному слову (не метке `[CLS]`), скрытое состояние относящееся к этой метке должно содержать в себе аггрегированное представление всего предложения, которое дальше будет использоваться для классификации. Таким образом, когда мы скормили предложение в процессе обучения сети, выходом будет вектор со скрытым состоянием, относящийся к метке `[CLS]`. Дополнительный полносвязный слой, который мы добавили, имеет размер `[hidden_state, количество_классов]`, в нашем случае количество классов равно двум. То есть нав выходе мы получим два числа, представляющих классы \"положительная эмоциональная окраска\" и \"отрицательная эмоциональная окраска\".\n","\n","Процесс дообучения достаточно дешев. По факту мы тренируем наш верхний слой и немного меняем веса во всех остальных слоях в процессе, чтобы подстроиться под нашу задачу.\n","\n","Иногда некоторые слои специально \"замораживают\" или применяют разные стратегии работы с learning rate, в общем, делают все, чтобы сохранить \"хорошие\" веса в нижних слоях и ускорить дообучение. В целом, замораживание слоев BERTа обычно не сильно сказывается на итоговом качестве, однако надо помнить о тех случаях, когда данные, использованные для предобучения и дообучения очень разные (разные домены или стиль: академическая и разговорная лексика). В таких случаях лучше тренировать все слои сети, не замораживая ничего."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"WnQW9E-bBCRt"},"source":["Загружаем BERT. `bert-base-uncased` - это версия \"base\" (в оригинальной статье рассказывается про две модели: \"base\" vs \"large\"), где есть только буквы в нижнем регистре (\"uncased\")."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"gFsCTp_mporB","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1597686988411,"user_tz":-180,"elapsed":31800,"user":{"displayName":"Максим Мухортов","photoUrl":"","userId":"13948818793795969641"}},"outputId":"979f52df-2b21-4dca-cd4e-6e06255de881"},"source":["model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n","model.to(device)"],"execution_count":28,"outputs":[{"output_type":"stream","text":["100%|██████████| 433/433 [00:00<00:00, 178929.42B/s]\n","100%|██████████| 440473133/440473133 [00:11<00:00, 39577373.02B/s]\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"markdown","metadata":{"id":"B7vPxqEAg8XY","colab_type":"text"},"source":["Теперь обсудим гиперпараметры для обучения нашей модели. Авторы статьи советуют выбирать `learning rate` `5e-5`, `3e-5`, `2e-5`, а количество эпох не делать слишком большим, 2-4 вполне достаточно. Мы пойдем еще дальше и попробуем дообучить нашу модель всего за одну эпоху."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"QxSMw0FrptiL","colab":{},"executionInfo":{"status":"ok","timestamp":1597686993418,"user_tz":-180,"elapsed":716,"user":{"displayName":"Максим Мухортов","photoUrl":"","userId":"13948818793795969641"}}},"source":["param_optimizer = list(model.named_parameters())\n","no_decay = ['bias', 'gamma', 'beta']\n","optimizer_grouped_parameters = [\n","    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n","     'weight_decay_rate': 0.01},\n","    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n","     'weight_decay_rate': 0.0}\n","]\n","\n","optimizer = AdamW(optimizer_grouped_parameters, lr=2e-5)\n","\n"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"6J-FYdx6nFE_","colab":{"base_uri":"https://localhost:8080/","height":329},"executionInfo":{"status":"ok","timestamp":1597690590041,"user_tz":-180,"elapsed":3554760,"user":{"displayName":"Максим Мухортов","photoUrl":"","userId":"13948818793795969641"}},"outputId":"0a62f959-bc55-42e9-bce2-c7dee0883f96"},"source":["from IPython.display import clear_output\n","\n","# Будем сохранять loss во время обучения\n","# и рисовать график в режиме реального времени\n","train_loss_set = []\n","train_loss = 0\n","\n","\n","# Обучение\n","# Переводим модель в training mode\n","model.train()\n","\n","\n","for step, batch in enumerate(train_dataloader):\n","    # добавляем батч для вычисления на GPU\n","    batch = tuple(t.to(device) for t in batch)\n","    # Распаковываем данные из dataloader\n","    b_input_ids, b_input_mask, b_labels = batch\n","    \n","    # если не сделать .zero_grad(), градиенты будут накапливаться\n","    optimizer.zero_grad()\n","    \n","    # Forward pass\n","    loss = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n","\n","    train_loss_set.append(loss[0].item())  \n","    \n","    # Backward pass\n","    loss[0].backward()\n","    \n","    # Обновляем параметры и делаем шаг используя посчитанные градиенты\n","    optimizer.step()\n","\n","    # Обновляем loss\n","    train_loss += loss[0].item()\n","    \n","    # Рисуем график\n","    clear_output(True)\n","    plt.plot(train_loss_set)\n","    plt.title(\"Training loss\")\n","    plt.xlabel(\"Batch\")\n","    plt.ylabel(\"Loss\")\n","    plt.show()\n","    \n","print(\"Loss на обучающей выборке: {0:.5f}\".format(train_loss / len(train_dataloader)))\n","\n","\n","# Валидация\n","# Переводим модель в evaluation mode\n","model.eval()\n","\n","valid_preds, valid_labels = [], []\n","\n","for batch in validation_dataloader:   \n","    # добавляем батч для вычисления на GPU\n","    batch = tuple(t.to(device) for t in batch)\n","    \n","    # Распаковываем данные из dataloader\n","    b_input_ids, b_input_mask, b_labels = batch\n","    \n","    # При использовании .no_grad() модель не будет считать и хранить градиенты.\n","    # Это ускорит процесс предсказания меток для валидационных данных.\n","    with torch.no_grad():\n","        logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n","\n","    # Перемещаем logits и метки классов на CPU для дальнейшей работы\n","    logits = logits[0].detach().cpu().numpy()\n","    label_ids = b_labels.to('cpu').numpy()\n","    \n","    batch_preds = np.argmax(logits, axis=1)\n","    batch_labels = np.concatenate(label_ids)     \n","    valid_preds.extend(batch_preds)\n","    valid_labels.extend(batch_labels)\n","\n","print(\"Процент правильных предсказаний на валидационной выборке: {0:.2f}%\".format(\n","    accuracy_score(valid_labels, valid_preds) * 100\n","))"],"execution_count":30,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZwcdZ3/8ddnJlwKCMio3IkYwCyugDHq4nqiBlSCorvgseKuP9ZV1F3ZdcOqiIAC4gUa5BDwAgICwkASwpUQcpKb3MnkIhMScieTTDLn5/dHV89U93TP9FXT3VPv5+ORR7qqq6u+9Z3u+tT3qO/X3B0REYmvmnInQEREykuBQEQk5hQIRERiToFARCTmFAhERGJOgUBEJOYUCCT2zGyCmX2l1NvmmYYPmVljqfcrkotB5U6ASCHMbG9o8XVAC9ARLP+7u9+X677c/fwothWpFgoEUpXc/fDkazNbB3zN3Z9N387MBrl7e3+mTaTaqGpIBpRkFYuZ/a+ZbQbuNbOjzexJM9tqZjuD1yeGPjPZzL4WvL7MzKaa2c+Dbdea2fkFbjvEzKaYWZOZPWtmY8zsLzmex9uDY+0ysyVmdmHovQvMbGmw341m9t/B+mODc9tlZjvM7EUz029c+qQviQxEbwGOAU4BLifxPb83WD4Z2A/8tpfPvwdYARwL/Ay428ysgG3vB14C3ghcA3w5l8Sb2UHAE8DTwJuAbwH3mdnpwSZ3k6j+OgI4E3g+WH8l0AjUAW8G/g/QGDLSJwUCGYg6gR+5e4u773f37e7+iLs3u3sT8BPgg718fr273+XuHcAfgeNIXFhz3tbMTgbeDVzt7q3uPhWozzH97wUOB24MPvs88CRwafB+GzDMzI50953uPi+0/jjgFHdvc/cXXYOJSQ4UCGQg2uruB5ILZvY6M7vDzNab2R5gCnCUmdVm+fzm5At3bw5eHp7ntscDO0LrADbkmP7jgQ3u3hlatx44IXh9MXABsN7MXjCz9wXrbwYagKfNbI2Zjc7xeBJzCgQyEKXfBV8JnA68x92PBD4QrM9W3VMKm4BjzOx1oXUn5fjZV4GT0ur3TwY2Arj7bHcfRaLa6DHgoWB9k7tf6e5vBS4EvmtmHy3yPCQGFAgkDo4g0S6wy8yOAX4U9QHdfT0wB7jGzA4O7to/nePHZwHNwPfM7CAz+1Dw2bHBvr5oZm9w9zZgD4mqMMzsU2b2tqCNYjeJ7rSdmQ8h0k2BQOLg18BhwDZgJvBUPx33i8D7gO3A9cCDJJ536JW7t5K48J9PIs23Af/i7suDTb4MrAuqub4eHAdgKPAssBeYAdzm7pNKdjYyYJnakkT6h5k9CCx398hLJCL5UIlAJCJm9m4zO9XMasxsJDCKRJ2+SEXRk8Ui0XkL8CiJ5wgagf9w9/nlTZJIT6oaEhGJOVUNiYjEXNVVDR177LE+ePDgcidDRKSqzJ07d5u712V6r+oCweDBg5kzZ065kyEiUlXMbH2291Q1JCIScwoEIiIxp0AgIhJzCgQiIjGnQCAiEnMKBCIiMadAICISc7EJBLPX7eAXT6+gtV3Ds4uIhMUmEMxdv5PfPN9Ae6cCgYhIWGwCQU0wKaHG2BMRSRWbQGDB9LSdigQiIiniEwiSJYLyJkNEpOLEKBAkIoEKBCIiqeITCIL/NRGPiEiq+AQCNRaLiGQUn0AQ/K84ICKSKjaBoKYm2UagUCAiEhabQJAsEXQqDoiIpIg0EJjZSDNbYWYNZjY6w/u/MrMFwb+VZrYrwsQA4KocEhFJEdmcxWZWC4wBPgY0ArPNrN7dlya3cff/Cm3/LeDsqNJTo0YCEZGMoiwRjAAa3H2Nu7cCY4FRvWx/KfBAVInpfrI4qiOIiFSnKAPBCcCG0HJjsK4HMzsFGAI8n+X9y81sjpnN2bp1a0GJ6X6yWJFARCSsUhqLLwEedveOTG+6+53uPtzdh9fV1RV0gMcXbATgb/M3FpxIEZGBKMpAsBE4KbR8YrAuk0uIsFoIYMOO/QCs3rIvysOIiFSdKAPBbGComQ0xs4NJXOzr0zcyszOAo4EZEaaFQbWJuiHNRyAikiqyQODu7cAVwERgGfCQuy8xs2vN7MLQppcAYz3iJ70GBd2G2jvURiAiEhZZ91EAdx8PjE9bd3Xa8jVRpiGpNggEHeo2JCKSolIaiyOX7D6qXkMiIqniEwg0+qiISEaxCQQ1pgfKREQyiU0g6C4RKBKIiITFLxCUNxkiIhUnPoEAzUcgIpJJbAJBjUoEIiIZxSYQoMZiEZGMYhMIzj/zLQCcefyRZU6JiEhliU0g+OQ7jgPgrXWHlzklIiKVJTaBIKlTjcUiIiliEwhq1FosIpJRbAJBcsrixp3NZU2HiEiliU8gCCLBrc83lDchIiIVJjaBIDnWkIiIpIpNIFAYEBHJLDaBQJFARCSzSAOBmY00sxVm1mBmo7Ns809mttTMlpjZ/VGmR0REeopsqkozqwXGAB8DGoHZZlbv7ktD2wwFrgLOdfedZvamqNIjIiKZRVkiGAE0uPsad28FxgKj0rb5f8AYd98J4O5bIkyPiIhkEGUgOAHYEFpuDNaFnQacZmbTzGymmY2MMD0iIpJBZFVDeRx/KPAh4ERgipm9w913hTcys8uBywFOPvnkwo6kJ4pFRDKKskSwETgptHxisC6sEah39zZ3XwusJBEYUrj7ne4+3N2H19XVRZZgEZE4ijIQzAaGmtkQMzsYuASoT9vmMRKlAczsWBJVRWsiTJOIiKSJLBC4eztwBTARWAY85O5LzOxaM7sw2GwisN3MlgKTgP9x9+1RpOeIQw+KYrciIlUv0jYCdx8PjE9bd3XotQPfDf5F6rCDazn6dQfx6XceH/WhRESqSnyeLAbMTPMRiIikiVcgABQHRERSxSsQmHqRioiki1kgMJUIRETSxCsQAK5IICKSIl6BwNRGICKSLl6BAMPVSiAikiJWgaBGJQIRkR5iFQgSzxGUOxUiIpUlVoGgubWd5tb2cidDRKSixCoQ7GxuY8LizeVOhohIRYlVIBARkZ4UCEREYk6BQEQk5hQIRERiToFARCTmyj15fb/64Gl17GpuLXcyREQqSqxKBLU1RoceLRYRSRFpIDCzkWa2wswazGx0hvcvM7OtZrYg+Pe1KNNTY0ZnZ5RHEBGpPpFVDZlZLTAG+BjQCMw2s3p3X5q26YPufkVU6QirMTRVpYhImihLBCOABndf4+6twFhgVITH61NtjdGhwYZERFJEGQhOADaElhuDdekuNrOXzexhMzsp047M7HIzm2Nmc7Zu3VpwgmpqNHm9iEi6cjcWPwEMdve/B54B/phpI3e/092Hu/vwurq6gg9Wo9FHRUR6iDIQbATCd/gnBuu6uPt2d28JFn8PvCvC9FBrqGpIRCRNlIFgNjDUzIaY2cHAJUB9eAMzOy60eCGwLML0UKM2AhGRHiLrNeTu7WZ2BTARqAXucfclZnYtMMfd64Fvm9mFQDuwA7gsqvQA1Jpp8noRkTSRPlns7uOB8Wnrrg69vgq4Kso0hNWYHigTEUlX7sbifpWoGip3KkREKkusAkFtDaoaEhFJE6tAoKohEZGe4hcI1GtIRCRFrAJBbY2hAoGISKpYBYIaPVAmItJDvAKB5iMQEekhVoGg1oxOlQhERFLEKxDUGO2dri6kIiIhsQoErz8k8SD1nv3tZU6JiEjliFUgOGRQ4nQ1J4GISLdYBYIaMwAUBkREusUqEARxQCUCEZGQmAWCoESgOCAi0iVegSD4X72GRES6xSoQqI1ARKSnWAUCtRGIiPQUaSAws5FmtsLMGsxsdC/bXWxmbmbDo0xPTRAIFAdERLpFFgjMrBYYA5wPDAMuNbNhGbY7AvgOMCuqtHQdK2glUIlARKRbToHAzF5vZjXB69PM7EIzO6iPj40AGtx9jbu3AmOBURm2uw64CTiQR7oLYioRiIj0kGuJYApwqJmdADwNfBn4Qx+fOQHYEFpuDNZ1MbNzgJPcfVxvOzKzy81sjpnN2bp1a45JzrgfQIFARCQs10Bg7t4MfBa4zd0/D/xdMQcOShi/BK7sa1t3v9Pdh7v78Lq6uoKP2dVGoH5DIiJdcg4EZvY+4ItA8u69to/PbAROCi2fGKxLOgI4E5hsZuuA9wL1UTYYd/caiuoIIiLVJ9dA8J/AVcDf3H2Jmb0VmNTHZ2YDQ81siJkdDFwC1CffdPfd7n6suw9298HATOBCd5+T91nkqOs5AtUNiYh0GZTLRu7+AvACdFXpbHP3b/fxmXYzuwKYSKL0cE8QRK4F5rh7fW+fj5JKBCIi3XIKBGZ2P/B1oIPEnf6RZnaLu9/c2+fcfTwwPm3d1Vm2/VAuaSmGSgQiIj3lWjU0zN33ABcBE4AhJHoOVRUNMSEi0lOugeCg4LmBi4B6d2+jCq+nGmJCRKSnXAPBHcA64PXAFDM7BdgTVaKioiEmRER6yrWx+Fbg1tCq9Wb24WiSFCUNMSEiki7XISbeYGa/TD7da2a/IFE6qCoqEYiI9JRr1dA9QBPwT8G/PcC9USUqKhpiQkSkp5yqhoBT3f3i0PKPzWxBFAmKkoaYEBHpKdcSwX4ze39ywczOBfZHk6ToaIgJEZGeci0RfB34k5m9IVjeCXwlmiRFx/RAmYhID7n2GloIvNPMjgyW95jZfwIvR5m4UktOXq8SgYhIt7xmKHP3PcETxgDfjSA9kUo+WVyFz8KJiESmmKkqre9NKkt/tRFMWr6FpgNt0R5ERKREigkEVXdbXdMP3Uc37trPV/8wm/96sOo6VYlITPXaRmBmTWS+4BtwWCQpilCyCLOvtT2yY+wP9r12277IjiEiUkq9lgjc/Qh3PzLDvyPcPdceRxUj2Wvoq/fOjvxYVVdcEpHYKqZqqOpYv7RqVF3TiYjEXKwCQU3/RAKRAeWb98/jN8+tKncyJEIxCwTlToFI9Rn38iZ+8czKcidDIhRpIDCzkWa2wswazGx0hve/bmaLzGyBmU01s2FRpqdWkUBEpIfIAoGZ1QJjgPOBYcClGS7097v7O9z9LOBnwC+jSg/AQbX9WACqktbi1/Yc4Jv3z2N/a0e5kyIiZRLllXEE0ODua9y9FRgLjApvEHpKGRLzG0R6+eyPQFBtzRA3PbWccS9vYtyiTeVOioiUSZRdQE8ANoSWG4H3pG9kZt8kMVzFwcBHMu3IzC4HLgc4+eSTC07QoNoqu0qLiPSDsjcWu/sYdz8V+F/gB1m2udPdh7v78Lq6uoKPdVBN2U9XBqjd+9u4Yfwy2jo6y50UkbxFeWXcCJwUWj4xWJfNWOCiCNOTUiLQDzZQJW0Zle6mp5Zzx5Q11C94tdxJEclblIFgNjDUzIaY2cHAJUB9eAMzGxpa/CQQaWflcCBYvXVvlIfS9TVmWtsTNxYdmutCqlBkbQTu3m5mVwATgVrgHndfYmbXAnPcvR64wszOA9roh8luwlVDUf1eq64VouoSXOEUB6QKRTpekLuPB8anrbs69Po7UR4/3UGDugPBl34/i7k//Fh/Hl4GMMVTqWaxaj0dFHqgbPu+1jKmpILoDlYk9mIVCPr1gbIqoztakfiK1ZWxP4eY8AIbIWas3k5zhPMlZKOCQWm4clKqUKwCQX+wIh4tfnXXfi69ayb//deFJUxRH1QUKIlqe6K8mrW0d/DLZ1ZyoE3DopSKAkEFSZYEVmxu6r+DVuANbGt7p2Z4k6z+PGM9tz63ijunrCl3UgYMBQIBKqtg8MPHFvPhn09mhxr0JYNkSUAlgtJRIKgguTQrzFi9nQdeeiX6xJTRtNXbANjX0v9tJcUq9vmU9o5Olm/e0/eGMVZM9atkpkAQkahqXC69ayZXPbqo5PutwBqiqmIlKlPd9NRyRv76RVWNSb9SICixYi4HutGRea/sAmD73pYyp0TiRIGggpRzmBrFoMqiElrflEelo0BQpdZt28fg0eN4esnmcidFQnRxkmqkQFBBslUNHWjr4K4pa+jo7L7MLGxMVCE88XJpZhbTBaw4qtaTaqZAEJFSVvP89vkGfjJ+GY/MbcxwnPwOtLelnXumri34yeeBZndzG/dOK11+FLsbxZPc6StcOrEOBFNWbi13ElJk+2I3HWgDYF8Jhp647omlXPvkUiavSD33uF6AvvfIQn78xFLmb9hV7qRIjlT6Kr1YB4Jbnyv9PDhRfElL2W969/5EUNlfxMM4nZ3O4ws2plRVVaud+xL5kZxYplLobrdv/T2uk7tz99S1A7JHV6wDQaXJ53qfDA75/hRKEVMenb+R74xdwD1T1xa/swpRbLaUKlbH/W735cZdDB49jjnrdpQ7KT0s3riH655cyncf6sexwPqJAkGJzF2/k7FFPvHb111gpdwlJu+ItjQdKHNKKo9GHy1Osrp20ootZU5JT63BPOd7gqragSTSQGBmI81shZk1mNnoDO9/18yWmtnLZvacmZ0SZXrSlfIne/HvpjO6RE/89scj9MUElWTyKiUwSbyU6ilu6RZZIDCzWmAMcD4wDLjUzIalbTYfGO7ufw88DPwsqvRkEmXPmWLuDHNJV/KnMO7lTQwePS7nOu5SxJiB9EOs1Dt49erKgbKoZKIsEYwAGtx9jbu3AmOBUeEN3H2SuzcHizOBEyNMT78o10XyQLtGYiyvgRMcJX6iDAQnABtCy43Bumz+DZiQ6Q0zu9zM5pjZnK1bS9fls1JvKLJVDZUyvck74WL2Wan5V07luJF3d/48Y11FjNba2t7JiJ88y4RFxT3oqAJR/6qIxmIz+xIwHLg50/vufqe7D3f34XV1dSU7brV82brr5ItPcClKLAOpZ0syS82M2et2sLfMF9NC/j4vrtrGDx9fwrVPLI0gRblzd5Zt2sOWphaueWJJ3p/f3dzGL59Z2ed2Xb+HvI8g2UQZCDYCJ4WWTwzWpTCz84DvAxe6+8DroFvhirmmV0sgzcXO5lY+f/sMvv3A/HInJW/NrYlqwR3N5Z3I555p6xg1ZhpQ2HfjunFL6ewKzNm3G0D3IRUjykAwGxhqZkPM7GDgEqA+vIGZnQ3cQSIIVF5/sSL090Uy3+OVIn1RN7T2Zx4mZ7ta+mphk8IMpFJSoaY3bCvq88U85CjFiSwQuHs7cAUwEVgGPOTuS8zsWjO7MNjsZuBw4K9mtsDM6rPsLpo0RrDPSJ4sznAPVPBx0j5XSB50Pcw2gEoEpRLnLAmfe1wCY2t7Jx/5+WQmV+BzD/mItI3A3ce7+2nufqq7/yRYd7W71wevz3P3N7v7WcG/C3vfY2ktrOLxZdKDQ3/+8PrrUP1xTsmLV6mf3bj1uVUMHj2Ozn4YhiMuF910ldDFdtPu/azZto+rH8+/TaSSVERjcbmt27aPB2dX9zzAeVcNBf/H9BrSQzIfiq3uSu7n18+uDPZXmPJf4vpfrt/FuAa+KA0qdwLK7Zr6JTwyr5GmA+3887tPLndyMirlF1+/oWilX8ATd6355/qYSQ28Z8gxVTtRewXcrEdmIJ5b7EsEf5i+jqYDPbsMHmjrYMe+wnthRPFliWSfBXymSq9NGSWrF4o9p/SPF3sBf3HVNtZvb+57wwEknGe5fNcH4gW5XGIfCLL5zG3TOee6Z8qdDCC/+8mOTqeto+/hJtLrVwu5blVCHW2pJNtcij6ltB3kvbvQ36GjyvK3v74P5Xp6/+LfTU8cfwDdCCUpEGSxbFNh3QjDVm/dy+DR45j/ys4SpCg3o8ZMZej3Mz6gDfTy1HIev+Hu+vTeXXDLi/x55vqs73/rgfmcde3TuR9YYmMgXmwrmQJBhF4IZgF7fMGrJdlfuCEz2w9l8cb8Ali+v7etTS1cEzzB2lfwWLppDz98bHHW959Y+Cq7mitvSN/d+9v4/O3T2bCj+KqZYm6Sy/FsSKWolnOplnT2RYEgJNei7YYdzTQdaKOz07ln6lr2t3Y/CFPMcBB9fWJBBN1d803lfbOy3+FXs3BgfWrxJmav25nXDHbpgbnQXkipuynuKvPEwleZtWZ7UfuoZP15DR5I1aCZKBDkaPyiTXz+9kQd4T/+bBKf/s1UJizezLVPLuXmiSu6tgvPHJZ+cbhxwnJeXFX4oHnjF20u+LNJ2UoAuRbF+/o9tHd0FtXIXm6JPj6pmdHZ6bTn0O6S/HzKchmvH996YD7/fOfM8iUgT9XYfbSS0lIMBYKQrb3MRfqN++Yxe113Xf+67c1dk8kn5wEOy3QBuP2F1Xz57peyHiOfi3S5vn+3hO6SM93tXvXoIs657pmSzAHcHxfRjM9TBAvLNieq2T7zu+m8rZd2l0xKcYHI9fwHyLUoUuu27WPiksJvpAZ4gUCBIOzpJa/ltX2mH2AxRcj+Ler2vlyoJ19ODD+cS8+lShK+cCdfJttbyvUEeukrF6PlWV4XIpdA2pLHHBwf/sVk/v3Pc4tI0cCmQFACme6MHeeFYP7VfINDlHd43UP4Fn/RyHRaJX34rQy3uoUGxGxdGvuzsbjahf/euZz7X2a+wu4cOxsUm5fZPl7oflvbO5lZQe03CgQhTmJi9umrixtFERJfkMkrCmsPSP9ulfLp0mLbCMJ6+w1UyzWs+4fcnQHF5HfX/AbJ5xKqJidKq79i+LZ91Tly/Q0TlnHJnTNZvHF3uZMCaIiJHi65cyartuzN+n5fd/fJrqL5FJPnrt/J6w+ppTbLBaia6oC7esuU4Ha2P++IM1UNlUPKXXGOQaRah6GoJqXuNbTqtcQ1ZmeZ55BIil2J4PIPvDXrez98bHGvQSBdph9gsgdRPt+bi383nZG/fnFAtBEk82TO+v57iK4QK19r4pG5jRneKe1fQVVDvXu5cReNOwt/XmPF5iYWNVbGXXWU1m7bx7NL82vDzEfsAkGxkb0/fpy53N8VehNYyrvH3vLiq/fOLnr/H7h5EqN+O7Xo/WTy8V9N4cq/Lsz4Xq5ZtHHXfnYFd3Q9PlOC6RSrLRCE05tr0i/87TTef9MkIJ/uo91bfuO+eXw6ou9IbmlJ/L9x134Gjx7HU4vzm6s5l79xW0cnH/75ZL72pzkFpDA3sQsEkXRmyfjH7PsvvL+1o2tmLIBJy7fk+MncDzd73Q7m5TDERbaL37a9LRm7x2Y7aKkrKRYGd3vTV29LeT5hz4E2bpiwrOjeSckzmLh4c7Df3OcsPvfG5zn3xudT1v2oPnVc+uJ6keX32f4IHDPXbOefbp+R83MVA0VfjcUdwbwTj8zrMRtv0fJ5sLFQsQsEI4Ycnfdnwt0HU2Zh6uUz6T/KTBOUvP3qpzjjh091Ld8wYXnmnRVxdf387TP47G3T+0xfNsOvf5Z3X/8sQErQ6k/Nre184a5ZfPH3s7rW/WLiCu54YQ1/m1/cDy/5t3002E9re2fWvFnUuJumA6lBcV9rB4sad5csAJZrQLVcXfnQQl5at4PNew4Uva/m1tyDblipcqito5N3/Ggij+XwHQoPhTL/lV1ZA3x49damFraUIJ9eKcFQJ32JNBCY2UgzW2FmDWY2OsP7HzCzeWbWbmafizItSR854815f6Y5NIRE9rvjVOlfk3ddn/tIprl90Qv7ORTyqdaOTrbvbUkJWgB7W3oGhqaW3H7c4xflXoT+QTBe0YrN3eMotQZ3pO0d/Vd/8unfTuVrf+xZPO+taqJcVUO5dqssp+89/HLKcjHVloU8zb5nfxtNLe1c++TSPrf98RO5zkDW/Ud790+eZcRPn8s7XeUQWSAws1pgDHA+MAy41MyGpW32CnAZcH9U6Uh38KDiTjnXoanDdwzusDOPH+aqLXuZu35HXunKtxrhyr8uZPPuA2zendsdy2t7enbTe2JhYYPptbZ38o375uW8fbHj8l/16CKufChze0C+5uf4cFl376mSHDajvS3trN++L2NwH3nLlF4/29np7OyHoUD+Nr+RwaPHZbwzLsUIv0nnXPcMd05ZXbL9pUsvDWf7u7onSk3VNodxlCWCEUCDu69x91ZgLDAqvIG7r3P3l4GKrnDs6yKb6d3whb+QvuQX/25G1+tSVheE79inNmxjRuihlm17W9gbvL+/tYOP/+qFvPa99NXcftjpP9gLbnmRJa8W1vMjl7x94KVXeGReIy3tHV11ub3p7cY07+6xEfYa+sJdM/ngzZMzvrepjwD/62dXcvZ1z7C1KZp++Mn93jllLQA/f3pFb5vnJdvf56fjs1St5mHhhl09BnfctreFRWn9/bO2GQCPzGvkshJ0lgB4avHmko1e3JsoA8EJwIbQcmOwrqos2LCLmWsy353nWpL9y8zKmQ95V6jfcvrFbPj1z/KRn08GYOmm3ax8rbsrbS7num77vozr567fkVJ0Tx96eummPfzsqewXiswX3fyD4+k/eIpT/298Xg3Mo8ZMSz1qcNhX0y606dUaJRlrqI8o8nJat8lFG3dz+g8msKWp71LexGA4lW2h8bUWbtjFum2Z/4aZTFqxhRsmLAulN1VLe0fXXf9DcxJddTs7ncGjx/GrZ1b2zLOcj1x6d09dy+DR4xg1ZhoXpf3NL7jlxR4l4uxtBKUtAj48d0PfG5VAVTQWm9nlZjbHzOZs3Vr46J2FuGjMtD5b7csxRG36hSY9Cbn0Oc6U7C3BnVz6e8Vc2C7+3Qw+d/t0Vr7WlBKIsmncuT/j+mSS5qzbwf6goXFfSzt3vLC6R2P8lqYDzFid+RH+O17IvQohfZyhA219B5HP3jata7veLubffmA+X757Vko/+PR83rmvNecB/LY0tdDS3smLK/t+Mj7T33PUmGl8KLgRyGTo98ezcVf33+ar987mjhfWZN0+03wOyVnXbnluVa/VkhOXbO566vb+Wa8wePS4nAL49l4GjuzN7b18J7bkUWoq9Erwl5nrM+ZXDgXYkogyEGwETgotnxisy5u73+nuw919eF1dXUkSV00KuQh/75HUhrg7XljN9U8u5dVd3T++3i5Spf7+rdm6j4//akrWhtXejhe+c9y8+wCfu30GjwXF5Z+OX84NE5bz9NLUkSUv+u00Lr0r8xDM2/b2Hoxyies1aX+T8F34vFdCvcxC+5q8YgvfGTu/a7l+4au8uGpb1jxp63DOvu4ZvnHfPOoXvso7rpmYMSgUM7/ZwGMAAA9YSURBVLR5Jss37+H6J5f2uMFpCzXM55JH5/2yZztF+HN7e+lYsHrrPj71m0S+3DA+UerIpUF4YWP2Hj2lVMqxh5pb2/nBY4u5JMOQ4f11kxllIJgNDDWzIWZ2MHAJUB/h8WKt5zj4qWtumLCc309dm3JHl+07Nnj0uB5d6nJpp8jlO7thx/5eL/qZ7vr2BRcMg66hv9Ol36mnV92UWnp+ZJsrInyul907O2t976TlW9i0O7UklJwj99llr3Hdk0tpOtCesUQ1MW3U3Ez5u/K1Jkb9dmqPO+a7pqzp8V35wl2z+P3UtSx5dU/O7T7Q90Vr3is7s5YCso2585NxS7vatX4+cQWrt+7lx09k7+Xzr3+Yw91T19K4szmvtOcrearLN6ceo5DLdnJfG3ftp72jkw07mhn70isF768QkY015O7tZnYFMBGoBe5x9yVmdi0wx93rzezdwN+Ao4FPm9mP3f3vokpTqVXSEC/7Wtrz7ucf/pJ9N61XzX2zomvXuHvq2h7rOjo7uaZ+CSOGHNPjveWbmwCCSWMyy1a6GTx6XI91DX0MI9LX33X73ha+/cD83jfK01f/MJtjDz+E0958eMb3k3fDmc4y/dzTL8jhPPhR/RJ++4VzupYfnb+Ry84dzN+feFSPzyfvyEvls7dN71GSSvrUb6by2bN7NiHe9WL3d2XHvlYezjgsSKrrxy3j+nGJUsT9X3sP//C2Y7veu/W5VdwzbS33XPZuTjnmdV37TdfS3sEhg2qzHsNxFm/czdf/ktr7bcrK4kpn33v4ZWat3cHGXfsZddYJ/VY1FOmgc+4+Hhiftu7q0OvZJKqMqlpUf6tP/eZFlm9qyjg+UvrY6p/93fSUHiBmxqQ+urBV0hAG0xq2M61hO3/pZbJ7d7I+QNYZKhD0NfbM1Ibe69D7mgnu1udW8dK63Lr35lO037a3JaXxNizZ2ynT7jJ17c0mU9VSe39dbei9zruzj7zqcM/7O3vjU8upv+L9Xcu/fGYlkAhKc39wXtbPnf6Dp1h7wwW9PtvQV8+s3nQPB5964/Ho/I0celBN8J4PiKqhAa/Qbp3zXtmZ8U413eKNe3L+kaZ3A3T3Psf7eXBO7j0Scin9lGLI5b7O9zfPN2Q5drdix555dlnvDe27cnyoEBLn89yy11L60Xd0On+asa6gtL33hr4fUMqli+z+tNJjOEDk88xLKT3WRzfJXM4rXXrPqrC+9vbU4s1ZHyB179kNOlevbG9mWnAzcqCtg6mrMt+Y9OdT5hqGugTyDdq5FG+LlcuPOZ+Zt/r6Sra2dzL6kUU576/UOt3Zvb+NZyIcoTEpn37dX7nnpa6qraT6hRu5+vFcn1Ttacbq7Vm76gKMfjT73+Hppa/1uAk50NbBv/+5uAHNHp3XyItZLmil0ule0vkd+vrd/kcfDz2Gp67NxwduntT1+urHF2fompr4//YXVjM9S8+3UlMgKMKYSYm70/o8n7A90JpfXX4ltUWkO/vap3nsm+dy8e+m99oLJHIO7/zx0+U7fhbpQQDgvx4s7innbL2hCvXw3EYm5TmJUrjTAfQcbC8Ke/MYEDAXRQ0IWMBHZ63Zzj+n9QzqrVrvln4YbC5JVUNFyGfugrBHixworZLsbG7jgzdP7rNLZtT6ql+W7LI9b9GbcFfHjk6nqcQX6UwWNu4uaYNcruNiZZLv8Cr7Wtp7BIFKokAgOfnYr3ofu6bcnlteXWO7VJJiGj2BnIY5L6dsAxx+9Bf5DaES9kKevYM+3MuDeulaenmAMKrGYwUCGRD6o21AMit2Toh8PF9AwM9ngMNc5Vtdm8/Tyb0ppME8FwoEIlKUL9w1q++NSqTQ6thSe7pMNx4dKhGUzrGHH1LuJORlzKTohtcVkfzlOv4TwG2TM3d5LkRnRIWvWAaCKz9+WrmTICIx0dvIuvlSiaCEznjLEeVOgohI3tryKInkI5aB4OyTj+bT7zy+3MkQEcnLnS9mH/a7GLEMBAC/ufTscidBRCQvr0U0qm5sA4GISLVpU/dREZF4a4/omQ0FAhGRKhGeJa6UFAhERKpEe0QPEigQiIhUCQ0xEYG6I6rrCWMRyc3n31X1Ex9mFNW4TpEGAjMbaWYrzKzBzEZneP8QM3sweH+WmQ2OMj3pZn//PB75j/f15yFFRArWXm1tBGZWC4wBzgeGAZea2bC0zf4N2OnubwN+BdwUVXqyedcpx/Dsdz/Q34cVEclbNXYfHQE0uPsad28FxgKj0rYZBfwxeP0w8FHrbbboiLztTUew7sZP8sd/HdHfhxaRCBx+6MCcfDGqi2OUuXUCEJ4dvRF4T7Zt3L3dzHYDbwRSJj81s8uBywFOPvnkqNLLB0+rY92NnyRID50OtTVGW0cnu5rbaOvo5PijDmPG6u2cdMxhKZ8dM6mB8888jn8ceix/ndvI+992LCN/PYXvjTyDD51ex+MLXmX1lr389ydOZ/ve1pQJ1occ+3pOrXs90xq2s7+tg5F/9xaeWrI5Yxrf+PqD+a+PncbF55zI+EWbqKmBtnZnxWtN3D11LZ85+wSOOHQQq7fu5YSjDuOq89/Otx6Yz/LNTZz+lsOZ1rCd97/tWNo7O5m5Zgf/O/IMbnpqecZjnXnCkTS3drBma+r8uP88/CS+9N5TeOPhB/MPNz4PkJLmb3zoVG6bvJqPnvEmGrbuZf32Zi77h8H8Yfq6Pv8Go846vmtO4Nu/dA5f/0vpxpI/66SjWJBhnuYvvfdkLjjzOB6YvYFzT31jr3P+5uLGz74j531888Ondo0ue9hBtRz1uoPYtPsAP/nMmQyqMfa2dDB+0Sbmrs8++ctpbz6cla/1Pjzz0DcdzvrtzbSWuI75orOO7zHp/EVnHc/3Rp7ByF9P4Y//OoJr6pckZhcLXPPpYVzzxNKs+/zBJ99Opzs/HZ/5e5nJsOOOZOmmPQD8zydO56vnDubeaetStrnwnccz75WdNO7cn2EPuTvv7W9mysqtKXl508XvYPKKrUxYnPl3W4hT617P6rTf3n+eN7Rk+w+zqGa8MbPPASPd/WvB8peB97j7FaFtFgfbNAbLq4Ntss6CPXz4cJ8zp7iJtkVE4sbM5rr78EzvRVk1tBE4KbR8YrAu4zZmNgh4A5D/BKoiIlKwKAPBbGComQ0xs4OBS4D6tG3qga8Erz8HPO9RFVFERCSjyNoIgjr/K4CJQC1wj7svMbNrgTnuXg/cDfzZzBqAHSSChYiI9KNIm9bdfTwwPm3d1aHXB4DPR5kGERHpXayfLBYREQUCEZHYUyAQEYk5BQIRkZiL7IGyqJjZVmB9gR8/lrSnlmNO+dGT8iSV8iNVNefHKe5el+mNqgsExTCzOdmerIsj5UdPypNUyo9UAzU/VDUkIhJzCgQiIjEXt0BwZ7kTUGGUHz0pT1IpP1INyPyIVRuBiIj0FLcSgYiIpFEgEBGJudgEAjMbaWYrzKzBzEaXOz1RMbN7zGxLMOlPct0xZvaMma0K/j86WG9mdmuQJy+b2Tmhz3wl2H6VmX0l07GqgZmdZGaTzGypmS0xs+8E62OZJ2Z2qJm9ZGYLg/z4cbB+iJnNCs77wWDoeMzskGC5IXh/cGhfVwXrV5jZJ8pzRqVhZrVmNt/MngyW45Uf7j7g/5EYBns18FbgYGAhMKzc6YroXD8AnAMsDq37GTA6eD0auCl4fQEwgcRUqO8FZgXrjwHWBP8fHbw+utznVmB+HAecE7w+AlgJDItrngTndXjw+iBgVnCeDwGXBOtvB/4jeP0N4Pbg9SXAg8HrYcHv6BBgSPD7qi33+RWRL98F7geeDJZjlR9xKRGMABrcfY27twJjgVFlTlMk3H0KibkdwkYBfwxe/xG4KLT+T54wEzjKzI4DPgE84+473H0n8AwwMvrUl567b3L3ecHrJmAZibmyY5knwXklJzg+KPjnwEeAh4P16fmRzKeHgY+amQXrx7p7i7uvBRpI/M6qjpmdCHwS+H2wbMQsP+ISCE4ANoSWG4N1cfFmd98UvN4MvDl4nS1fBmR+BcX4s0ncBcc2T4JqkAXAFhIBbTWwy93bg03C59Z13sH7u4E3MoDyA/g18D0gORv9G4lZfsQlEEjAE+XY2PUZNrPDgUeA/3T3PeH34pYn7t7h7meRmEd8BHBGmZNUNmb2KWCLu88td1rKKS6BYCNwUmj5xGBdXLwWVG8Q/L8lWJ8tXwZUfpnZQSSCwH3u/miwOtZ5AuDuu4BJwPtIVIElZywMn1vXeQfvvwHYzsDJj3OBC81sHYkq448AtxCz/IhLIJgNDA16AhxMopGnvsxp6k/1QLKXy1eAx0Pr/yXoKfNeYHdQXTIR+LiZHR30pvl4sK7qBPW3dwPL3P2XobdimSdmVmdmRwWvDwM+RqLdZBLwuWCz9PxI5tPngOeDElQ9cEnQi2YIMBR4qX/OonTc/Sp3P9HdB5O4Ljzv7l8kbvlR7tbq/vpHojfIShL1od8vd3oiPM8HgE1AG4l6yn8jUYf5HLAKeBY4JtjWgDFBniwChof2868kGrwagK+W+7yKyI/3k6j2eRlYEPy7IK55Avw9MD/Ij8XA1cH6t5K4cDUAfwUOCdYfGiw3BO+/NbSv7wf5tAI4v9znVoK8+RDdvYZilR8aYkJEJObiUjUkIiJZKBCIiMScAoGISMwpEIiIxJwCgYhIzCkQiGRgZh1mtiAYpXOemf1DH9sfZWbfyGG/k81swE1+LtVNgUAks/3ufpa7vxO4Crihj+2PIjEypUjVUSAQ6duRwE5IjFlkZs8FpYRFZpYcxfZG4NSgFHFzsO3/BtssNLMbQ/v7fDAnwEoz+8f+PRWRngb1vYlILB0WjNB5KIk5DT4SrD8AfMbd95jZscBMM6snMafBmZ4YzA0zO5/E0MTvcfdmMzsmtO9B7j7CzC4AfgSc10/nJJKRAoFIZvtDF/X3AX8yszNJDEHxUzP7AIlhi0+gewjrsPOAe929GcDdw3NEJAe+mwsMjib5IrlTIBDpg7vPCO7+60iMU1QHvMvd24JRKw/Nc5ctwf8d6DcoFUBtBCJ9MLMzSEx3up3EsMNbgiDwYeCUYLMmElNhJj0DfNXMXhfsI1w1JFJRdDciklmyjQAS1UFfcfcOM7sPeMLMFgFzgOUA7r7dzKaZ2WJggrv/j5mdBcwxs1ZgPPB/ZTgPkT5p9FERkZhT1ZCISMwpEIiIxJwCgYhIzCkQiIjEnAKBiEjMKRCIiMScAoGISMz9f2U/p1jbUDSqAAAAAElFTkSuQmCC\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"stream","text":["Loss на обучающей выборке: 0.03682\n","Процент правильных предсказаний на валидационной выборке: 98.10%\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2W3J7ewVg8Xe","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1597690590805,"user_tz":-180,"elapsed":740,"user":{"displayName":"Максим Мухортов","photoUrl":"","userId":"13948818793795969641"}},"outputId":"d4403d1f-3296-46e8-a365-a717e27f789e"},"source":["print(\"Процент правильных предсказаний на валидационной выборке: {0:.2f}%\".format(\n","    accuracy_score(valid_labels, valid_preds) * 100\n","))"],"execution_count":31,"outputs":[{"output_type":"stream","text":["Процент правильных предсказаний на валидационной выборке: 98.10%\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"mkyubuJSOzg3"},"source":["# Оценка качества на отложенной выборке"]},{"cell_type":"markdown","metadata":{"id":"5ZG_PGKng8Xh","colab_type":"text"},"source":["Качество на валидационной выборке оказалось очень хорошим. Не переобучилась ли наша модель?"]},{"cell_type":"markdown","metadata":{"id":"bQvirU-Wg8Xi","colab_type":"text"},"source":["Делаем точно такую же предобработку для тестовых данных, как и в начале ноутбука делали для обучающих данных:"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"mAN0LZBOOPVh","colab":{},"executionInfo":{"status":"ok","timestamp":1597690623872,"user_tz":-180,"elapsed":33798,"user":{"displayName":"Максим Мухортов","photoUrl":"","userId":"13948818793795969641"}}},"source":["tokenized_texts = [tokenizer.tokenize(sent) for sent in test_sentences]\n","input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n","\n","input_ids = pad_sequences(\n","    input_ids,\n","    maxlen=100,\n","    dtype=\"long\",\n","    truncating=\"post\",\n","    padding=\"post\"\n",")"],"execution_count":32,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MZrVdgfOg8Xk","colab_type":"text"},"source":["Создаем attention маски и приводим данные в необходимый формат:"]},{"cell_type":"code","metadata":{"id":"0XdpD0xbg8Xk","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597690628307,"user_tz":-180,"elapsed":38230,"user":{"displayName":"Максим Мухортов","photoUrl":"","userId":"13948818793795969641"}}},"source":["attention_masks = [[float(i>0) for i in seq] for seq in input_ids]\n","\n","prediction_inputs = torch.tensor(input_ids)\n","prediction_masks = torch.tensor(attention_masks)\n","prediction_labels = torch.tensor(test_gt)\n","\n","prediction_data = TensorDataset(\n","    prediction_inputs,\n","    prediction_masks,\n","    prediction_labels\n",")\n","\n","prediction_dataloader = DataLoader(\n","    prediction_data, \n","    sampler=SequentialSampler(prediction_data),\n","    batch_size=32\n",")"],"execution_count":33,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Hba10sXR7Xi6","colab":{},"executionInfo":{"status":"ok","timestamp":1597691246777,"user_tz":-180,"elapsed":474227,"user":{"displayName":"Максим Мухортов","photoUrl":"","userId":"13948818793795969641"}}},"source":["model.eval()\n","test_preds, test_labels = [], []\n","\n","for batch in prediction_dataloader:\n","    # добавляем батч для вычисления на GPU\n","    batch = tuple(t.to(device) for t in batch)\n","    \n","    # Распаковываем данные из dataloader\n","    b_input_ids, b_input_mask, b_labels = batch\n","    \n","    # При использовании .no_grad() модель не будет считать и хранить градиенты.\n","    # Это ускорит процесс предсказания меток для тестовых данных.\n","    with torch.no_grad():\n","        logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n","\n","    # Перемещаем logits и метки классов на CPU для дальнейшей работы\n","    logits = logits[0].detach().cpu().numpy()\n","    label_ids = b_labels.to('cpu').numpy()\n","\n","    # Сохраняем предсказанные классы и ground truth\n","    batch_preds = np.argmax(logits, axis=1)\n","    batch_labels = np.concatenate(label_ids)  \n","    test_preds.extend(batch_preds)\n","    test_labels.extend(batch_labels)"],"execution_count":34,"outputs":[]},{"cell_type":"code","metadata":{"id":"EkKd2nwXg8Xq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1597691246780,"user_tz":-180,"elapsed":473802,"user":{"displayName":"Максим Мухортов","photoUrl":"","userId":"13948818793795969641"}},"outputId":"ba7a720a-e8c5-4c0d-a103-c26422302e69"},"source":["acc_score = accuracy_score(test_labels, test_preds)\n","print('Процент правильных предсказаний на отложенной выборке составил: {0:.2f}%'.format(\n","    acc_score*100\n","))"],"execution_count":35,"outputs":[{"output_type":"stream","text":["Процент правильных предсказаний на отложенной выборке составил: 98.16%\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"b-P--IsGg8Xs","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":215},"executionInfo":{"status":"error","timestamp":1597691248521,"user_tz":-180,"elapsed":1718,"user":{"displayName":"Максим Мухортов","photoUrl":"","userId":"13948818793795969641"}},"outputId":"ccc736f3-27ee-4893-e9cb-819f2d608dc5"},"source":["print('Неправильных предсказаний: {0}/{1}'.format(\n","    sum(test_labels != test_preds),\n","    len(test_labels)\n","))"],"execution_count":36,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-36-564f4a8b4f2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m print('Неправильных предсказаний: {0}/{1}'.format(\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_labels\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtest_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m ))\n","\u001b[0;31mTypeError\u001b[0m: 'bool' object is not iterable"]}]},{"cell_type":"markdown","metadata":{"id":"foeuXNIzg8Xu","colab_type":"text"},"source":["### Оценка качества работы без fine-tuning"]},{"cell_type":"code","metadata":{"id":"Bdg-KpBfg8Xu","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1597691248514,"user_tz":-180,"elapsed":1698,"user":{"displayName":"Максим Мухортов","photoUrl":"","userId":"13948818793795969641"}}},"source":["model_wo_finetuning = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n","model_wo_finetuning.cuda()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"L646MFJdg8Xw","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1597691248517,"user_tz":-180,"elapsed":1697,"user":{"displayName":"Максим Мухортов","photoUrl":"","userId":"13948818793795969641"}}},"source":["model_wo_finetuning.eval()\n","preds_wo_finetuning, labels_wo_finetuning = [], []\n","\n","for batch in prediction_dataloader:\n","    batch = tuple(t.to(device) for t in batch)\n","    b_input_ids, b_input_mask, b_labels = batch\n","    with torch.no_grad():\n","        logits = model_wo_finetuning(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n","\n","    logits = logits[0].detach().cpu().numpy()\n","    label_ids = b_labels.to('cpu').numpy()\n","\n","    batch_preds = np.argmax(logits, axis=1)\n","    batch_labels = np.concatenate(label_ids)  \n","    preds_wo_finetuning.extend(batch_preds)\n","    labels_wo_finetuning.extend(batch_labels)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"m4OcAWkzg8Xy","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1597691248517,"user_tz":-180,"elapsed":1685,"user":{"displayName":"Максим Мухортов","photoUrl":"","userId":"13948818793795969641"}}},"source":["acc_score_wo_finetuning = accuracy_score(labels_wo_finetuning, preds_wo_finetuning)\n","print('Процент правильных предсказаний на отложенной выборке составил: {0:.2f}%'.format(\n","    acc_score_wo_finetuning*100\n","))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"filR7gdog8X0","colab_type":"text"},"source":["Сравним точность и полноту предсказаний:"]},{"cell_type":"code","metadata":{"id":"o5yaz6lcg8X1","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1597691248520,"user_tz":-180,"elapsed":1677,"user":{"displayName":"Максим Мухортов","photoUrl":"","userId":"13948818793795969641"}}},"source":["from sklearn.metrics import recall_score, precision_score\n","\n","print('1 эпоха: точность (precision) {0:.2f}%, полнота (recall) {1:.2f}%'.format(\n","    precision_score(test_labels, test_preds) * 100,\n","    recall_score(test_labels, test_preds) * 100\n","))\n"," \n","print('Без дообучения: точность (precision) {0:.2f}%, полнота (recall) {1:.2f}%'.format(\n","    precision_score(labels_wo_finetuning, preds_wo_finetuning) * 100,\n","    recall_score(labels_wo_finetuning, preds_wo_finetuning) * 100,\n","))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CtchOC1ig8X4","colab_type":"text"},"source":["Итак, мы показали, что предобученный BERT может быстро (всего за одну эпоху) давать хорошее качество при решении задачи анализа эмоциональной окраски текстов. Обратите внимание, что мы не тюнили параметры и использовали сравнительно небольшой размеченный корпус, чтобы получить accuracy больше 98\\%. Тем не менее, если не делать дообучения под конкретную задачу вовсе, получить хорошее качество не удается.\n","\n","Кроме того, мы познакомились с библиотекой `pytorch-transformers`, которая позволяет использовать готовые обертки над моделями, специально созданными для решения той или иной задачи. Использовать BERT при решении повседневных NLP задач совсем нетрудно: не нужно даже вручную скачивать веса модели, библиотека все сделает за вас. Отбросив необходимость чуть-чуть предобработать тексты, сложность применения предобученного BERT'а оказывается не сильно больше, чем импортировать и применить лог.регрессию из `sklearn`."]}]}